{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## is GPU on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.python.client import device_lib\n",
    "# print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## boilerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
    "from numpy import arange\n",
    "\n",
    "MODEL_NAME = 'mobilenet'\n",
    "IMG_SIZE = (224, 224)\n",
    "INPUT_SHAPE=(224, 224, 3)\n",
    "CLASSES = 2\n",
    "FT_BLOCK = 10 # FROM feature extractor TO fine tuning scratch\n",
    "BATCH_SIZE = 64 # these data points will be passed as a batch at one time to the network\n",
    "# PR_RATIO = 50\n",
    "tag = 'mobilenet_BS64_FT100_PR50'\n",
    "\n",
    "INPUT_MODEL = f'../../models/PR/{tag}'\n",
    "MODEL_DIR = '../../models/QT/'\n",
    "MODEL_FILE_TFLITE = MODEL_DIR+f'{tag}.tflite'\n",
    "MODEL_FILE_TFLITE_FT16 = MODEL_DIR+f'{tag}_ft16.tflite' \n",
    "MODEL_FILE_TFLITE_INT16 = MODEL_DIR+f'{tag}_int16.tflite' \n",
    "MODEL_FILE_TFLITE_INT8 = MODEL_DIR+f'{tag}_int8.tflite'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "from json import dump\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "import shutil\n",
    "from keras.models import load_model\n",
    "import tempfile\n",
    "import tensorflow_model_optimization as tfmot\n",
    "import tensorflow as tf\n",
    "\n",
    "def get_gzipped_model_size(file):\n",
    "    # Returns size of gzipped model, in bytes.\n",
    "    import os\n",
    "    from zipfile import ZipFile, ZIP_DEFLATED\n",
    "    import tempfile\n",
    "    \n",
    "    _, zipped_file = tempfile.mkstemp('.zip')\n",
    "    with ZipFile(zipped_file, 'w', compression=ZIP_DEFLATED) as f:\n",
    "        f.write(file)\n",
    "\n",
    "    return os.path.getsize(zipped_file) / float(2**20)\n",
    "\n",
    "def get_file_size(file):\n",
    "    from os import stat\n",
    "    return stat(file).st_size / float(2**20)\n",
    "\n",
    "\n",
    "def unzip_model(target_dir, model_file):\n",
    "    from os import remove\n",
    "    from zipfile import ZipFile\n",
    "    \n",
    "    with ZipFile(model_file, 'r') as f:\n",
    "        f.extractall(target_dir)\n",
    "        target_name = f.namelist()[0]\n",
    "        tmp = target_dir+'/'+target_name\n",
    "        pruned_model = load_model(tmp)\n",
    "        remove(tmp)\n",
    "        pruned_model.compile(loss='binary_crossentropy', metrics='accuracy', optimizer = 'adam')\n",
    "    return pruned_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD THE PRUNED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Saved pruned Keras model to: /tmp/tmpvy6ftjad.h5\n",
      "Size of pruned Keras model: 12.57 MB\n",
      "Size of gzipped pruned Keras model: 7.29 MB\n"
     ]
    }
   ],
   "source": [
    "input_model_zip = f'{INPUT_MODEL}.zip'\n",
    "input_model_dir = f'../../models/PR'\n",
    "\n",
    "pruned_keras_file = unzip_model(input_model_dir, input_model_zip)\n",
    "# pruned_keras_file.evaluate(test_ds)\n",
    "\n",
    "model_for_export = tfmot.sparsity.keras.strip_pruning(pruned_keras_file)\n",
    "\n",
    "_, pruned_keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
    "print('Saved pruned Keras model to:', pruned_keras_file)\n",
    "\n",
    "target_file = f'{INPUT_MODEL}.h5'\n",
    "shutil.move(pruned_keras_file, target_file)\n",
    "print(\"Size of pruned Keras model: %.2f MB\" % (get_file_size(target_file)))\n",
    "print(\"Size of gzipped pruned Keras model: %.2f MB\" % (get_gzipped_model_size(target_file)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUANTIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_dir = '../../data/test/'\n",
    "test_ds = image_dataset_from_directory(\n",
    "    directory=test_dir,\n",
    "    label_mode='binary',\n",
    "    batch_size=1000,\n",
    "    image_size=IMG_SIZE)\n",
    "\n",
    "test_images, test_labels = next(iter(test_ds))\n",
    "\n",
    "# A helper function to evaluate the TF Lite model using \"test\" dataset.\n",
    "def evaluate_model(interpreter):\n",
    "    import numpy as np\n",
    "        \n",
    "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "    output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "    # Run predictions on every image in the \"test\" dataset.\n",
    "    prediction = []\n",
    "    test_time = 0\n",
    "    for test_image in test_images:\n",
    "        # Pre-processing: add batch dimension and convert to float32 to match with\n",
    "        # the model's input data format.\n",
    "        test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
    "        interpreter.set_tensor(input_index, test_image)\n",
    "\n",
    "        # Run inference.\n",
    "        starttime = timer()\n",
    "        interpreter.invoke()\n",
    "        test_time += (timer()-starttime)\n",
    "\n",
    "        # Post-processing: remove batch dimension and \n",
    "        # find the digit with highest probability.\n",
    "        output = interpreter.tensor(output_index)\n",
    "        digit = np.argmax(output()[0])\n",
    "        prediction.append(digit)\n",
    "\n",
    "    # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "    accurate_count = 0\n",
    "    for index in range(len(prediction)):\n",
    "        if prediction[index] == test_labels[index]:\n",
    "            accurate_count += 1\n",
    "    accuracy = accurate_count * 1.0 / len(prediction)\n",
    "\n",
    "    return accuracy, test_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: /tmp/tmprd53yvru/assets\n",
      "Size of gzipped pruned TFlite model: 7.15 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/tf/kim/gramstain/model/QT/mobilenet_BS64_FT100_PR50.tflite'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_for_export = load_model(target_file)\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "pruned_tflite_model = converter.convert()\n",
    "\n",
    "_, pruned_tflite_file = tempfile.mkstemp('tflite')\n",
    "with open(pruned_tflite_file, 'wb') as f:\n",
    "    f.write(pruned_tflite_model)\n",
    "print(\"Size of gzipped pruned TFlite model: %.2f MB\" % (get_gzipped_model_size(pruned_tflite_file)))\n",
    "\n",
    "target_file = MODEL_FILE_TFLITE\n",
    "shutil.move(pruned_tflite_file, target_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.5 36.33864077180624\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=str(MODEL_FILE_TFLITE))\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "acc, e_time = evaluate_model(interpreter)\n",
    "print(acc*100, e_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpi6j9fpv7/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpi6j9fpv7/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of gzipped pruned and quantized TFlite (float 16) model: 4.02 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/tf/kim/gramstain/model/QT/mobilenet_BS64_FT100_PR50_ft16.tflite'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "quantized_and_pruned_tflite_model = converter.convert()\n",
    "\n",
    "_, quantized_and_pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(quantized_and_pruned_tflite_file, 'wb') as f:\n",
    "  f.write(quantized_and_pruned_tflite_model)\n",
    "print(\"Size of gzipped pruned and quantized TFlite (float 16) model: %.2f MB\" % (get_gzipped_model_size(quantized_and_pruned_tflite_file)))\n",
    "\n",
    "target_file = MODEL_FILE_TFLITE_FT16\n",
    "shutil.move(quantized_and_pruned_tflite_file, target_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.4 36.44199927896261\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=str(MODEL_FILE_TFLITE_FT16))\n",
    "interpreter.allocate_tensors()\n",
    "acc, e_time = evaluate_model(interpreter)\n",
    "print(acc*100, e_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## int16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpbb0bb6ow/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpbb0bb6ow/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of gzipped pruned and quantized TFlite (int 16) model: 2.22 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/tf/kim/gramstain/model/QT/mobilenet_BS64_FT100_PR50_int16.tflite'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.EXPERIMENTAL_TFLITE_BUILTINS_ACTIVATIONS_INT16_WEIGHTS_INT8]\n",
    "quantized_and_pruned_tflite_model = converter.convert()\n",
    "\n",
    "_, quantized_and_pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(quantized_and_pruned_tflite_file, 'wb') as f:\n",
    "  f.write(quantized_and_pruned_tflite_model)\n",
    "print(\"Size of gzipped pruned and quantized TFlite (int 16) model: %.2f MB\" % (get_gzipped_model_size(quantized_and_pruned_tflite_file)))\n",
    "\n",
    "target_file = MODEL_FILE_TFLITE_INT16\n",
    "shutil.move(quantized_and_pruned_tflite_file, target_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.10000000000001 2437.689823202789\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=str(MODEL_FILE_TFLITE_INT16))\n",
    "interpreter.allocate_tensors()\n",
    "acc, e_time = evaluate_model(interpreter)\n",
    "print(acc*100, e_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## int8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9980 files belonging to 2 classes.\n",
      "Using 8982 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_dir = '../../data/train/'\n",
    "train_ds = image_dataset_from_directory(\n",
    "    directory=train_dir,\n",
    "    label_mode='binary',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMG_SIZE,\n",
    "    seed=0,\n",
    "    validation_split=0.1,\n",
    "    subset='training')\n",
    "\n",
    "\n",
    "train_images, train_labels = next(iter(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_data_gen():\n",
    "    for input_value in tf.data.Dataset.from_tensor_slices(train_images).batch(1).take(100):\n",
    "    # Model has only one input so each data point has one element.\n",
    "        yield [input_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of gzipped pruned and quantized TFlite (int 8) model: 2.22 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/tf/kim/gramstain/model/QT/mobilenet_BS64_FT100_PR50_int8.tflite'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# Set the input and output tensors to uint8 (APIs added in r2.3)\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "_, quantized_and_pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(quantized_and_pruned_tflite_file, 'wb') as f:\n",
    "  f.write(quantized_and_pruned_tflite_model)\n",
    "print(\"Size of gzipped pruned and quantized TFlite (int 8) model: %.2f MB\" % (get_gzipped_model_size(quantized_and_pruned_tflite_file)))\n",
    "\n",
    "target_file = MODEL_FILE_TFLITE_INT8\n",
    "shutil.move(quantized_and_pruned_tflite_file, target_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_dir = '../../data/test/'\n",
    "test_ds = image_dataset_from_directory(\n",
    "    directory=test_dir,\n",
    "    label_mode='binary',\n",
    "    batch_size=1000,\n",
    "    image_size=IMG_SIZE)\n",
    "\n",
    "test_images, test_labels = next(iter(test_ds))\n",
    "\n",
    "# Helper function to evaluate a TFLite model on all images\n",
    "def evaluate_model(tflite_file, model_type):\n",
    "\n",
    "    test_image_indices = range(test_images.shape[0])\n",
    "    predictions, test_time = run_tflite_model(tflite_file, test_image_indices)\n",
    "\n",
    "    # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "    accurate_count = 0\n",
    "    for index in range(len(predictions)):\n",
    "        if predictions[index] == test_labels[index]:\n",
    "            accurate_count += 1\n",
    "    accuracy = accurate_count * 100 / len(predictions)\n",
    "\n",
    "    print(f'{model_type} model accuracy is {accuracy} (Number of test samples={len(test_images)})')\n",
    "    print('execution time: ', test_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to run inference on a TFLite model\n",
    "def run_tflite_model(tflite_file, test_image_indices):\n",
    "    global test_images\n",
    "\n",
    "    # Initialize the interpreter\n",
    "    interpreter = tf.lite.Interpreter(model_path=str(tflite_file))\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    input_details = interpreter.get_input_details()[0]\n",
    "#     print('input: ', input_details)\n",
    "    output_details = interpreter.get_output_details()[0]\n",
    "#     print('output: ', output_details)\n",
    "\n",
    "    predictions = []\n",
    "    test_time = 0\n",
    "    for i, test_image_index in enumerate(test_image_indices):\n",
    "        test_image = test_images[test_image_index]\n",
    "        test_label = test_labels[test_image_index]\n",
    "\n",
    "        # Check if the input type is quantized, then rescale input data to uint8\n",
    "        if input_details['dtype'] == np.uint8:\n",
    "            input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "            test_image = test_image / input_scale + input_zero_point\n",
    "\n",
    "        test_image = np.expand_dims(test_image, axis=0).astype(input_details[\"dtype\"])\n",
    "        interpreter.set_tensor(input_details[\"index\"], test_image)\n",
    "\n",
    "        starttime = timer()\n",
    "        interpreter.invoke()\n",
    "        test_time += (timer()-starttime)\n",
    "\n",
    "        output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "        predictions.append(output.argmax())\n",
    "    return predictions, test_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized model accuracy is 89.4 (Number of test samples=1000)\n",
      "execution time:  2881.4320004060864\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(MODEL_FILE_TFLITE_INT8, model_type=\"Quantized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
